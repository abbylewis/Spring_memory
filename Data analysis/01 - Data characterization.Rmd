---
title: "Data characterization"
author: "Abby Lewis"
date: "2023-05-22"
output: html_document
---

This code file performs basic characterization of the dataset and generates a map of study sites

Table of contents:

- Step 1: Load packages
- Step 2: Summary statistics
- Step 3: Map distribution of lakes


Step 1: Load packages

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(viridis)
library(lubridate)

# Make a directory for Figures if there isn't one
if (!dir.exists("../Figures")){dir.create("../Figures")}
```

Step 2: Summary statistics

```{r}
#Load data from EDI
lat_long <- read.csv("https://pasta.lternet.edu/package/data/eml/edi/1530/1/fadd3eaa25b5fdd1fc4efba70e660579")
#Load interpolated DO data file, created by "02 - Temp and DO interpolation.Rmd"
do <- read.csv("../Compiled data/temp_o2_interpolated.csv")
#Combine
full <- do %>%
  full_join(lat_long, by = c("LakeID")) %>%
  mutate(Date = as.Date(Date)) %>%
  filter(!is.na(MaximumDepth_m) & MaximumDepth_m >= 6.4)
#filter to rows with data
not_na <- full %>%
  filter(if_any(.cols = c(Temp_C,DO_mgL),
                .fns = ~ !is.na(.x)))

not_na%>%
  dplyr::summarise(profiles = length(unique(paste0(Date,LakeID))),
                   lakes = length(unique(LakeID)))

not_na%>%
  group_by(LakeID) %>%
  dplyr::summarize(duration = as.numeric(max(Date)-min(Date))/365+1) %>%
  ungroup() %>%
  dplyr::summarize(min_duration = min(duration, na.rm = T),
                   max_duration = max(duration, na.rm = T),
                   sd_duration = sd(duration, na.rm = T),
                   mean_duration = mean(duration, na.rm =T),
                   median_duration = median(duration, na.rm = T))

min(not_na$Date)
max(not_na$Date)

# Total number of profiles
not_na %>%
  select(LakeID, Date) %>%
  unique()

lat_long%>%
  ungroup() %>%
  filter(LakeID %in% not_na$LakeID) %>%
  dplyr::reframe(across(.cols = c(MaximumDepth_m, 
                                  SurfaceArea_ha, 
                                  Elevation_m, 
                                  Latitude_DD),
                          .fns = ~ c(median(.x,na.rm=T), 
                                     min(.x,na.rm=T), 
                                     max(.x,na.rm=T))))

unique(lat_long$Country)

#How many lakes are removed by 6.4 m depth cut off?
length(unique(lat_long$LakeID))-length(unique(lat_long$LakeID[is.na(lat_long$MaximumDepth_m)|lat_long$MaximumDepth_m>6.4])) #158
```

Step 3: Map distribution of lakes

```{r}
library(ggthemes)
library(sf)
library(rnaturalearth)
library(rnaturalearthdata)
#remotes::install_github("ropensci/rnaturalearthhires")
library(rnaturalearthhires)
library(ggspatial)

#Create a world map of the sites in this analysis
world <- ne_countries(scale = "medium", returnclass = "sf")
states <- ne_states(returnclass = "sf",country = "United States of America")
for_map <- read.csv("https://pasta.lternet.edu/package/data/eml/edi/1530/1/fadd3eaa25b5fdd1fc4efba70e660579")

for_map <- for_map %>%
  filter(MaximumDepth_m > 6.4)

jpeg("../Figures/World Map - just points.jpg", res = 300, width = 6, height = 3.2, units = "in")
world_map <- ggplot(data = world) +
  geom_sf(fill = "white", color = "grey60") +
  coord_sf(expand = FALSE)+
  geom_point(data = for_map, aes(Longitude_DD, Latitude_DD), 
             fill = "#3087D9",shape = 21, color = "white", size = 2, alpha  =.7, stroke = .4)+
  theme_bw()+
  theme(plot.margin = margin(0, 0, 0, 0, "cm"),
    legend.box.background = element_rect(fill = "white", color = "white"))+
  scale_fill_viridis(name = "Years of data")+
  theme(axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.background = element_rect(fill = "grey93"),
        panel.grid = element_blank())
world_map
dev.off()
```