---
title: "ISIMIP analysis"
author: "Abby Lewis"
date: "2024-01-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(ncdf4)
library(tidyverse)
library(lubridate)
library(rLakeAnalyzer)
source("../Data processing/thermo.depth.density.R")

lakes <- read.csv("lakes_for_isimip.csv")
lat_long <- read.csv("https://pasta.lternet.edu/package/data/eml/edi/1530/1/fadd3eaa25b5fdd1fc4efba70e660579")
```

Step 1: Make database of annual hypo and epi temps at each lake
```{r}
test <- nc_open("../External data/gotm_gfdl-esm2m_ewembi_historical_nosoc_co2_watertemp_global_daily_1991_2000.nc4")

Lon <- ncvar_get(test,"lon")
Lon <- ifelse(Lon > 180, -(360 - Lon), Lon)
Lat <- ncvar_get(test,"lat")
time <- ncvar_get(test,"time")
date <- as.Date("1661-01-01")+days(time)
levlak <- ncvar_get(test,"levlak")
fillvalue <- ncatt_get(test, "levlak","missing_value")
levlak[levlak == fillvalue$value] <- NA


#Loop through lakes and add temp data based on lat/lon
combined_t_df <- data.frame(LakeID = rep(lakes$LakeID, each = length(time)*dim(levlak)[3]),
                           Date = rep(as.Date("1661-01-01") + days(time), each = dim(levlak)[3]),
                           Depth_m = as.numeric(NA),
                           Temp_C = as.numeric(NA),
                           Lon = as.numeric(NA),
                           Lat = as.numeric(NA)
                           )
for(i in 1:nrow(lakes)){
  print(lakes$LakeID[i])
  lon_id <- ifelse(min(abs(lakes[i,]$Lon-Lon)) <= 0.25, 
                   which.min(abs(lakes[i,]$Lon - Lon)), 
                   NA)
  lat_id <- ifelse(min(abs(lakes[i,]$Lat-Lat)) <= 0.25, 
                   which.min(abs(lakes[i,]$Lat - Lat)), 
                   NA)
  if(!is.na(lon_id) & !is.na(lat_id)){
    depths <- ncvar_get(test,"levlak", start = c(lon_id, lat_id, 1), count = c(1,1,-1))
    t_vector <- ncvar_get(test,"watertemp", start = c(lon_id, lat_id, 1, 1), count = c(1,1,-1,-1))
    t_vector[t_vector == fillvalue$value] <- NA
    combined_t_df$Temp_C[combined_t_df$LakeID==lakes[i,]$LakeID]<- t_vector-273.15
    combined_t_df$Depth_m[combined_t_df$LakeID==lakes[i,]$LakeID]<- rep(depths, length(time))
    combined_t_df$Lon[combined_t_df$LakeID==lakes[i,]$LakeID]<- Lon[lon_id]
    combined_t_df$Lat[combined_t_df$LakeID==lakes[i,]$LakeID]<- Lat[lat_id]
  }
}

#look <- combined_t_df %>%
#  filter(month(Date) == 7)

isimip_summer <- combined_t_df %>%
  left_join(lat_long) %>%
  filter(((Latitude_DD>0) & 
            yday(Date) >= yday("2022-07-01") & 
            yday(Date) <= yday("2022-08-31")) |
           ((Latitude_DD<0) &
              yday(Date) >= yday("2022-01-01") & 
              yday(Date) <= yday("2022-02-28"))) 

thermo_depths <- isimip_summer %>%
  group_by(Date, LakeID)%>%
  dplyr::summarize(epi_depth = meta.depths(Temp_C,Depth_m,mixed.cutoff = 0)[1],
            hypo_depth = meta.depths(Temp_C,Depth_m,mixed.cutoff = 0)[2],
            max_depth = max(Depth_m),
            thermo = thermo.depth.density(Temp_C,Depth_m, mixed.cutoff = 0.1, seasonal = F))%>% #use custom density threshold function
  mutate(Year= year(Date),
         unstrat = as.numeric(is.na(thermo)))%>%
  group_by(Year,LakeID)%>%
  dplyr::summarize(epi_depth = mean(epi_depth, na.rm = T),
            hypo_depth = mean(hypo_depth, na.rm = T),
            count_unstrat = sum(unstrat),
            n = n())

#Remove years with unstratified profiles and lakes where 10% of years have unstratified profiles
thermo_depths_sum <- thermo_depths%>%
  group_by(LakeID)%>%
  dplyr::mutate(count_unstrat_tot = sum(count_unstrat),
                n = sum(n))%>%
  filter((count_unstrat_tot/n) <0.1,
         count_unstrat == 0)%>%
  group_by(LakeID,Year)%>%
  dplyr::summarize(epi_sd = sd(epi_depth, na.rm = T),
            epi_depth = mean(epi_depth, na.rm = T),
            hypo_sd = sd(hypo_depth, na.rm = T),
            hypo_depth = mean(hypo_depth, na.rm = T))

#Add thermocline depths
full_with_thermo <- isimip_summer %>%
  mutate(Year = year(Date))%>%
  full_join(thermo_depths_sum)%>%
  filter(!is.na(epi_depth),
         !is.na(hypo_depth),
         )
#Add discrete layer designations from data providers
summer_layers <- full_with_thermo %>%
  mutate(Layer = ifelse(!is.na(Depth_m)&Depth_m<epi_depth, "EPI", NA),
         Layer = ifelse(!is.na(Depth_m)&Depth_m>hypo_depth,"HYPO",Layer),
         Layer = ifelse(!is.na(Depth_m)&Depth_m<hypo_depth&Depth_m>epi_depth, "META",Layer))%>%
  filter(!is.na(Layer))

write.csv(summer_layers, "../Compiled data/ISIMIP_summer_layers2.csv", row.names = F)

unstrat <- combined_t_df %>%
  filter(Lat > 0,
         month(Date)<9) %>%
  group_by(Date, LakeID)%>%
  dplyr::summarize(max_depth = max(Depth_m),
            thermo = thermo.depth.density(Temp_C,Depth_m, mixed.cutoff = 0.1, seasonal = F))%>% 
  mutate(Year= year(Date),
         unstrat = as.numeric(is.na(thermo)))%>%
  filter(unstrat == 1,
         !max_depth > 1E19)

strat_onset <- unstrat %>%
  group_by(LakeID, Year) %>%
  filter(Date == max(Date),
         yday(Date) < yday("2022-08-30")) %>%
  group_by(LakeID) %>%
  summarize(strat_onset = median(yday(Date), na.rm = T))

write.csv(strat_onset, "../Compiled data/ISIMIP_strat_onset2.csv", row.names = F)

#Calculate averages
summer_avgs <- summer_layers%>%
  group_by(LakeID,Year, Layer)%>% #not separating by measurement location. Is this a problem?
  dplyr::summarize(Temp_C = mean(Temp_C, na.rm = T))
  
write.csv(summer_avgs, "../Compiled data/ISIMIP_summer_avgs2.csv", row.names = F)

strat_onset %>%
  filter(LakeID == "117")
```

Load air temp data

```{r}
lakes <- read.csv("lakes_for_isimip.csv")

process_tas <- function(file){
  file_nc <- nc_open(file)
  Lon <- ncvar_get(file_nc,"lon")
  Lon <- ifelse(Lon > 180, -(360 - Lon), Lon)
  Lat <- ncvar_get(file_nc,"lat")
  time <- ncvar_get(file_nc,"time")
  t_mean <- ncvar_get(file_nc,"tas")
  fillvalue <- ncatt_get(file_nc, "tas","missing_value") 
  t_mean[t_mean == fillvalue$value] <- NA
  
  #Loop through lakes and add temp data based on lat/lon
  combined_t_df <- data.frame(LakeID = rep(lakes$LakeID, each = length(time)),
                             Date = as.Date("1861-01-01") + days(time), 
                             Lon = as.numeric(NA),
                             Lat = as.numeric(NA)
                             )
  for(i in 1:nrow(lakes)){
    lon_id <- ifelse(min(abs(lakes[i,]$Lon-Lon))<=0.25,which.min(abs(lakes[i,]$Lon-Lon)),NA)
    lat_id <- ifelse(min(abs(lakes[i,]$Lat-Lat))<=0.25, which.min(abs(lakes[i,]$Lat-Lat)),NA)
    if(!is.na(lon_id)&!is.na(lat_id)){
      t_vector <- t_mean[lon_id,lat_id,] 
      combined_t_df$Temp_C[combined_t_df$LakeID==lakes[i,]$LakeID]<- t_vector-273.15
      combined_t_df$Lon[combined_t_df$LakeID==lakes[i,]$LakeID]<- Lon[lon_id]
      combined_t_df$Lat[combined_t_df$LakeID==lakes[i,]$LakeID]<- Lat[lat_id]
    }
  }
  return(combined_t_df)
}

gfdl_2001 <- process_tas('../External data/tas_day_GFDL-ESM2M_historical_r1i1p1_EWEMBI_20010101-20051231.nc4') 
gfdl_1991 <- process_tas('../External data/tas_day_GFDL-ESM2M_historical_r1i1p1_EWEMBI_19910101-20001231.nc4') 
gfdl_1981 <- process_tas('../External data/tas_day_GFDL-ESM2M_historical_r1i1p1_EWEMBI_19810101-19901231.nc4') 

air_temps <- gfdl_2001 %>%
  full_join(gfdl_1991) %>%
  full_join(gfdl_1981)

write.csv(air_temps, "../Compiled data/ISIMIP_GFDL_temp_1981_2005.csv", row.names = F)
```

